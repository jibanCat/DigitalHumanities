{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Naive import NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes -- Class to Calculate Single Phrase Posterior Probability \n",
    "\n",
    "This class is designed for calculating single phrase probability to classify a given property. We could either write our own definition of likelihoods of each feature, or simply load in my pre-defined `json` file.\n",
    "\n",
    "In this notebook, let's simply try my pre-defined `json` file for practice.\n",
    "\n",
    "Resources: \n",
    "- [Naive Bayes Probabilistic Model (wiki)](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Probabilistic_model)\n",
    "- [Naive Bayes for Text Classification (Andrew Ng's ML course).mp4](http://openclassroom.stanford.edu/MainFolder/courses/MachineLearning/videos/06.2-NaiveBayes-TextClassification.mp4)\n",
    "- [Naive Bayes for Spell Checker Python Code (Peter Norvig)](https://norvig.com/spell-correct.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Class\n",
    "\n",
    "I load the likelihood table from `definition_time.json` file, and set the prior probability for being a time phrase to be 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Naive import NaiveBayes\n",
    "\n",
    "naive = NaiveBayes(filename='definition_time.json', prior=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'columns'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definition table attribute\n",
    "naive.definition_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '(str) use few chars to represent the feature name',\n",
       " 'iterable': '(str, or any iterable) any iterable can be iterated',\n",
       " 'likelihood': '(float) the independent prob of the feature'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can check the columns inside it\n",
    "naive.definition_dict['columns']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterables and Likelihoods\n",
    "\n",
    "Iterable means the bag-of-characters (or bag-of-words) that you think they are belonging to certain type of feature. \n",
    "\n",
    "Say feature for 數字, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '數字', 'iterable': '是元正𨳝一二三四五六七八九十廿卅', 'likelihood': 0.6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive.definition_dict['data'][-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this means that we think the bag-of-chars `是元正𨳝一二三四五六七八九十廿卅` belonging to numbers and any time phrase would have 0.6 likelihood to have these numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Posterior Probability\n",
    "\n",
    "Once we have prior and likelihoods from `json`, we can calculate the posterior probability with a given phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428572"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simply use calc_posterior method\n",
    "naive.calc_posterior('興寧三年')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularize the Irrelevant Characters\n",
    "\n",
    "`naive.calc_posterior` method only consider the characters matched your given likelihoods and iterables. If you want to punish the irrelevant chars, simply use the `regularize` arg to set the punishment probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8571428571428572, 0.8571428571428572)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we don't set the regularization, \n",
    "# these 2 phrase would have the same posterior.\n",
    "naive.calc_posterior('興寧三年'), naive.calc_posterior('興寧三年你好嗎')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8571428571428572, 0.64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can set the regularize=0.4 to drag down the posterior of the second phrase \n",
    "naive.calc_posterior('興寧三年', regularize=0.4), naive.calc_posterior('興寧三年你好嗎', regularize=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add your Own Definition\n",
    "\n",
    "We can modify the definition dict to add new likelihoods and iterables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2924187725631769"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before adding 平成\n",
    "naive.calc_posterior(\"平成三十年\", regularize=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can add new definition of likelihood and a bag-of-words using dict\n",
    "new_definition = {\n",
    "    'name': '現代紀年', \n",
    "    'iterable': ['中華民國', '民國', '平成', '昭和', '西元', '西曆'], \n",
    "    'likelihood': 0.8\n",
    "}\n",
    "\n",
    "naive.definition_dict['data'].append(\n",
    "    new_definition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to json for new-time usage\n",
    "naive.to_json('definition_time_modern.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading again\n",
    "naive = NaiveBayes(filename=\"definition_time_modern.json\", prior=0.3)\n",
    "\n",
    "naive.calc_posterior(\"平成三十年\", regularize=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting Philosophical Article about Thomas Bayes\n",
    "\n",
    "- [Thomas Bayes and the crisis in science](https://www.the-tls.co.uk/articles/public/thomas-bayes-science-crisis/) by David Papineau: this article discuss the life of Thomas Bayes and why _inverse probability_ is interesting. Moreover, discuss about the over-used hypothesis testing and the ignorance of _prior probability_."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
