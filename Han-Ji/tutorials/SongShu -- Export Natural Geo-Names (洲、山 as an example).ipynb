{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# C-like numeric array\n",
    "import numpy as np\n",
    "\n",
    "# dealing with table data\n",
    "import pandas as pd\n",
    "\n",
    "# from `SongShu.py`\n",
    "from SongShu import SongShu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SongShu -- Export Natural Geo-Names (Ê¥≤„ÄÅÂ±± as an example)\n",
    "\n",
    "Natural geographical names are those names identified by natural scenes, e.g., mountains, rivers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Stop at loading data/ShongShu_0851.html.\n",
      "[Info] Total length of the data is 851.\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõ(P.625)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÂàù‰πãÂπ≥Êõ≤(P.644)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÊà∞ÊªéÈôΩÊõ≤(P.644)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÁç≤ÂëÇÂ∏ÉÊõ≤(P.644)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÂÖãÂÆòÊ∏°Êõ≤(P.645)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèËàäÈÇ¶Êõ≤(P.645)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÂÆöÊ≠¶ÂäüÊõ≤(P.645)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÂ±†Êü≥ÂüéÊõ≤(P.646)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÂπ≥ÂçóËçäÊõ≤(P.646)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÂπ≥Èóú‰∏≠Êõ≤(P.646)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÊáâÂ∏ùÊúüÊõ≤(P.646)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÈÇïÁÜôÊõ≤(P.647)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÈ≠èÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÁπÜË•≤ÔºèÂ§™ÂíåÊõ≤(P.647)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÁÇéÁ≤æÁº∫Êõ≤Âá°‰∏âÂçÅÂè•ÔºåÂè•‰∏âÂ≠ó(P.656)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÊº¢‰πãÂ≠£Êõ≤Âá°‰∫åÂçÅÂè•ÔºåÂÖ∂ÂçÅÂÖ´Âè•Âè•‰∏âÂ≠óÔºå‰∫åÂè•Âè•ÂõõÂ≠ó(P.656)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÊîÑÊ≠¶Â∏´Êõ≤Âá°ÂÖ≠Âè•ÔºåÂÖ∂‰∏âÂè•Âè•‰∏âÂ≠óÔºå‰∏âÂè•Âè•ÂõõÂ≠ó(P.657)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠Ôºè‰ºêÁÉèÊûóÊõ≤Âá°ÂçÅÂÖ´Âè•ÔºåÂÖ∂ÂçÅÂè•Âè•ÂõõÂ≠óÔºåÂÖ´Âè•Âè•‰∏âÂ≠ó(P.657)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÁßãÈ¢®Êõ≤Âá°ÂçÅ‰∫îÂè•ÔºåÂÖ∂ÂçÅÂõõÂè•Âè•‰∫îÂ≠óÔºå‰∏ÄÂè•ÂõõÂ≠ó(P.657)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÂÖãÁöñÂüéÊõ≤Âá°ÂçÅ‰∫åÂè•ÔºåÂÖ∂ÂÖ≠Âè•Âè•‰∏âÂ≠óÔºåÂÖ≠Âè•Âè•ÂõõÂ≠ó(P.657)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÈóúËÉåÂæ∑Êõ≤Âá°‰∫åÂçÅ‰∏ÄÂè•ÔºåÂÖ∂ÂÖ´Âè•Âè•ÂõõÂ≠óÔºå‰∫åÂè•Âè•ÂÖ≠Â≠óÔºå‰∏ÉÂè•Âè•‰∫îÂ≠óÔºåÂõõÂè•Âè•‰∏âÂ≠ó(P.658)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÈÄöËçäÈñÄÊõ≤Âá°‰∫åÂçÅÂõõÂè•ÔºåÂÖ∂ÂçÅ‰∏ÉÂè•Âè•‰∫îÂ≠óÔºåÂõõÂè•Âè•‰∏âÂ≠óÔºå‰∏âÂè•Âè•ÂõõÂ≠ó(P.658)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÁ´†Ê¥™Âæ∑Êõ≤Âá°ÂçÅÂè•ÔºåÂÖ∂ÂÖ´Âè•Âè•‰∏âÂ≠óÔºå‰∫åÂè•Âè•ÂõõÂ≠ó(P.659)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÂæûÊõÜÊï∏Êõ≤Âá°‰∫åÂçÅÂÖ≠Âè•ÔºåÂÖ∂‰∏ÄÂè•Âè•‰∏âÂ≠óÔºå‰∏âÂè•Âè•ÂõõÂ≠óÔºå‰∫åÂçÅ‰∫åÂè•Âè•‰∫îÂ≠óÔºå‰∏ÄÂè•ÂÖ≠Â≠ó(P.659)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÊâøÂ§©ÂëΩÊõ≤Âá°‰∏âÂçÅÂõõÂè•ÔºåÂÖ∂ÂçÅ‰πùÂè•Âè•‰∏âÂ≠óÔºå‰∫åÂè•Âè•‰∫îÂ≠óÔºåÂçÅ‰∏âÂè•Âè•ÂõõÂ≠ó(P.659)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑‰∫åÂçÅ‰∫å„ÄÄÂøóÁ¨¨ÂçÅ‰∫åÔºèÊ®ÇÂõõÔºèÂê≥ÈºìÂêπÊõ≤ÂçÅ‰∫åÁØá„ÄÄÈüãÊò≠ÔºèÁéÑÂåñÊõ≤Âá°ÂçÅ‰∏âÂè•ÔºåÂÖ∂‰∫îÂè•Âè•‰∫îÂ≠óÔºå‰∫åÂè•Âè•‰∏âÂ≠óÔºå‰∏âÂè•Âè•ÂõõÂ≠óÔºå‰∏âÂè•Âè•‰∏ÉÂ≠ó(P.660)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑ÂõõÂçÅ„ÄÄÂøóÁ¨¨‰∏âÂçÅÔºèÁôæÂÆò‰∏ãÔºèÁ¨¨‰∏ÄÂìÅ(P.1260)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑ÂõõÂçÅ„ÄÄÂøóÁ¨¨‰∏âÂçÅÔºèÁôæÂÆò‰∏ãÔºèÁ¨¨‰∫åÂìÅ(P.1260)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑ÂõõÂçÅ„ÄÄÂøóÁ¨¨‰∏âÂçÅÔºèÁôæÂÆò‰∏ãÔºèÁ¨¨‰∏âÂìÅ(P.1261)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑ÂõõÂçÅ„ÄÄÂøóÁ¨¨‰∏âÂçÅÔºèÁôæÂÆò‰∏ãÔºèÁ¨¨ÂõõÂìÅ(P.1261)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑ÂõõÂçÅ„ÄÄÂøóÁ¨¨‰∏âÂçÅÔºèÁôæÂÆò‰∏ãÔºèÁ¨¨‰∫îÂìÅ(P.1262)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑ÂõõÂçÅ„ÄÄÂøóÁ¨¨‰∏âÂçÅÔºèÁôæÂÆò‰∏ãÔºèÁ¨¨ÂÖ≠ÂìÅ(P.1263)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑ÂõõÂçÅ„ÄÄÂøóÁ¨¨‰∏âÂçÅÔºèÁôæÂÆò‰∏ãÔºèÁ¨¨‰∏ÉÂìÅ(P.1264)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑ÂõõÂçÅ„ÄÄÂøóÁ¨¨‰∏âÂçÅÔºèÁôæÂÆò‰∏ãÔºèÁ¨¨ÂÖ´ÂìÅ(P.1264)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n",
      "[Warning] Not the right indent. Âè≤ÔºèÊ≠£Âè≤ÔºèÂÆãÊõ∏ÔºèÂøó„ÄÄÂá°‰∏âÂçÅÂç∑ÔºèÂç∑ÂõõÂçÅ„ÄÄÂøóÁ¨¨‰∏âÂçÅÔºèÁôæÂÆò‰∏ãÔºèÁ¨¨‰πùÂìÅ(P.1265)..[Â∫ïÊú¨ÔºöÂÆãÂÖÉÊòé‰∏âÊúùÈÅû‰øÆÊú¨]\n"
     ]
    }
   ],
   "source": [
    "# Get the SongShu Text\n",
    "songshu = SongShu(\"2018-06-28\", \"MF\")\n",
    "songshu.load_htmls()\n",
    "\n",
    "# preprocessing the songshu data to get metadata and bookmarks\n",
    "# and separate the passages in every pages\n",
    "songshu.extract_paths()\n",
    "songshu.extract_meta()\n",
    "songshu.extract_passages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ê¥≤„ÄÅÂ±± as an Example\n",
    "\n",
    "We could use regex to list all possible phrases attached with Ê¥≤„ÄÅÂ±±,  \n",
    "e.g., 'È¨±Ê¥≤', 'ÂêëÈ¨±Ê¥≤', 'Ëµ∞ÂêëÈ¨±Ê¥≤', ...  \n",
    "and then use frequency to see which one is possible to be natural geographical names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a generator to list all n-gram phrase attached with Ê¥≤ and Â±±\n",
    "\n",
    "def regexf(char, num):\n",
    "    return r\"[^„ÄÅ„ÄÇÔºåÔºüÔºÅÔºöÔºõ„Äå„Äç„Äî„Äï„Äé„Äè]{\" + str(num) + \"}\" + char\n",
    "\n",
    "def passageGen():\n",
    "    for passages in songshu.flat_passages:\n",
    "        for p in passages:\n",
    "            yield p\n",
    "            \n",
    "def phraseCharGen(char, limits=(1, 4)):\n",
    "    lower, upper = limits\n",
    "    for p in passageGen() :\n",
    "        for i in range(lower, upper):\n",
    "            for match in re.finditer(regexf(char, i), p):\n",
    "                yield match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ëî°Ê¥≤', 14),\n",
       " ('È¨±Ê¥≤', 9),\n",
       " ('Â∂∏Ê¥≤', 6),\n",
       " ('Â¥¢Â∂∏Ê¥≤', 6),\n",
       " ('Ëá≥Ëî°Ê¥≤', 6),\n",
       " ('ÊñºÂ¥¢Â∂∏Ê¥≤', 5),\n",
       " ('Ëá™Ëî°Ê¥≤', 5),\n",
       " ('Èï∑Ê¥≤', 5),\n",
       " ('ËêΩÊ¥≤', 4),\n",
       " ('Ê°ëËêΩÊ¥≤', 4),\n",
       " ('‰∫îÊ¥≤', 4),\n",
       " ('Âæ™Ëá≥Ëî°Ê¥≤', 4),\n",
       " ('Ê∫ßÊ¥≤', 3),\n",
       " ('Ë≥äËá™Ëî°Ê¥≤', 3),\n",
       " ('Â±±Ê¥≤', 3)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(list(phraseCharGen('Ê¥≤', limits=(1, 4)))).most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ê≥∞Â±±', 58),\n",
       " ('Ê¢ÅÂ±±', 40),\n",
       " ('Á®ΩÂ±±', 28),\n",
       " ('ÊúÉÁ®ΩÂ±±', 28),\n",
       " ('‰∏≠Â±±', 23),\n",
       " ('ÁÇ∫Â±±', 19),\n",
       " ('ÈôΩÂ±±', 17),\n",
       " ('È´òÂ±±', 17),\n",
       " ('ÂêçÂ±±', 16),\n",
       " ('ÂçóÂ±±', 15),\n",
       " ('Âª¨Â±±', 14),\n",
       " ('ÈçæÂ±±', 13),\n",
       " ('ÊñºÂ±±', 12),\n",
       " ('Âè≤Â±±', 12),\n",
       " ('Âà∫Âè≤Â±±', 11),\n",
       " ('Â∑ûÂà∫Âè≤Â±±', 11),\n",
       " ('ÈÑíÂ±±', 10),\n",
       " ('Èô∞Â±±', 10),\n",
       " ('‰ª•Â±±', 9),\n",
       " ('ÊôØÈôΩÂ±±', 8)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(list(phraseCharGen('Â±±', limits=(1, 5)))).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there are some patterns here... Hmmm \n",
    "\n",
    "- We should count the longer phrase as the correct name (if two phrases have the same occurrences)\n",
    "- We can use correct phrase to search the direction verb (Ëá™„ÄÅËá≥„ÄÅÊñº) üòÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditioning on Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Ëî°Ê¥≤', 14),\n",
       "  ('È¨±Ê¥≤', 9),\n",
       "  ('Â¥¢Â∂∏Ê¥≤', 6),\n",
       "  ('Èï∑Ê¥≤', 5),\n",
       "  ('Ê°ëËêΩÊ¥≤', 4),\n",
       "  ('‰∫îÊ¥≤', 4),\n",
       "  ('Ê∫ßÊ¥≤', 3),\n",
       "  ('Â±±Ê¥≤', 3)],\n",
       " {'Êñº', 'Ëá™', 'Ëá≥'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I currently cannot figure out an imperative solution ...\n",
    "# though functinoal solution here would introduce more iterations ...\n",
    "def condition(counter):\n",
    "    exclude_set = set([(p1, n1) for p1,n1 in counter for p2,n2 in counter if (n1 == n2) and (p1 != p2) and (p1 in p2)])\n",
    "    argmax_set  = set([(p1, n1) for p1,n1 in counter if all([True if p2 not in p1 else False for p2,n2 in counter if (n2 > n1)])])\n",
    "    return sorted(argmax_set - exclude_set, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def condition_verb(counter):\n",
    "    regex = r\"([^„ÄÅ„ÄÇÔºåÔºüÔºÅÔºöÔºõ„Äå„Äç„Äî„Äï„Äé„Äè]{1})\" + r\"({})\".format(\"|\".join(p1 for p1,_ in condition(counter)))\n",
    "    return {match.group(1) for p,_ in counter for match in re.finditer(regex, p)}\n",
    "\n",
    "def geonames_and_verbs(char, limits=(1, 4), top_n=15):\n",
    "    counter = Counter(list(phraseCharGen(char, limits))).most_common(top_n)\n",
    "    return condition(counter), condition_verb(counter)\n",
    "    \n",
    "geonames_and_verbs('Ê¥≤', limits=(1, 4), top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems ok ...  \n",
    "so we got geo-names and the verbs attached with geo-names in a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Ê≥∞Â±±', 58),\n",
       "  ('Ê¢ÅÂ±±', 40),\n",
       "  ('ÊúÉÁ®ΩÂ±±', 28),\n",
       "  ('‰∏≠Â±±', 23),\n",
       "  ('ÁÇ∫Â±±', 19),\n",
       "  ('ÈôΩÂ±±', 17),\n",
       "  ('È´òÂ±±', 17),\n",
       "  ('ÂêçÂ±±', 16),\n",
       "  ('ÂçóÂ±±', 15),\n",
       "  ('Âª¨Â±±', 14),\n",
       "  ('ÈçæÂ±±', 13),\n",
       "  ('Âè≤Â±±', 12),\n",
       "  ('ÊñºÂ±±', 12),\n",
       "  ('ÈÑíÂ±±', 10),\n",
       "  ('Èô∞Â±±', 10),\n",
       "  ('‰ª•Â±±', 9)],\n",
       " {'Âà∫', 'ÊôØ'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geonames_and_verbs('Â±±', limits=(1, 4), top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something need to be manually exclude: Êñº„ÄÅÁÇ∫„ÄÅ‰ª•\n",
    "\n",
    "direction verbs finding seem to be failed if the geo-names are wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to apply on non-natural-geo-names: Â∑û"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Ë±´Â∑û', 448),\n",
       "  ('ÂæêÂ∑û', 364),\n",
       "  ('ËçäÂ∑û', 335),\n",
       "  ('ÊèöÂ∑û', 322),\n",
       "  ('ÂÖóÂ∑û', 312),\n",
       "  ('‰∫åÂ∑û', 274),\n",
       "  ('ÈõçÂ∑û', 232),\n",
       "  ('Ê±üÂ∑û', 210),\n",
       "  ('Âª£Â∑û', 168),\n",
       "  ('ÈùíÂ∑û', 167),\n",
       "  ('ÁõäÂ∑û', 150),\n",
       "  ('ÊπòÂ∑û', 146),\n",
       "  ('ÈÉ¢Â∑û', 126),\n",
       "  ('ÂéªÂ∑û', 124),\n",
       "  ('Âè∏Â∑û', 89),\n",
       "  ('Ê¢ÅÂ∑û', 85),\n",
       "  ('ÂÜÄÂ∑û', 82)],\n",
       " {'Âçó'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geonames_and_verbs('Â∑û', limits=(1, 4), top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Ê∞∏ÂàùÈÉ°', 202),\n",
       "  ('‰∫åÈÉ°', 154),\n",
       "  ('ÂçóÈÉ°', 137),\n",
       "  ('Âê≥ÈÉ°', 130),\n",
       "  ('Â∑ûÈÉ°', 64),\n",
       "  ('Èô≥ÈÉ°', 49),\n",
       "  ('Ë´∏ÈÉ°', 48),\n",
       "  ('Ê¢ÅÈÉ°', 47),\n",
       "  ('ÈôΩÈÉ°', 45),\n",
       "  ('‰∏âÈÉ°', 43),\n",
       "  ('Êù±ÈÉ°', 42),\n",
       "  ('Ê≤õÈÉ°', 35),\n",
       "  ('Âπ≥ÈÉ°', 33),\n",
       "  ('‰∫îÈÉ°', 33),\n",
       "  ('ËúÄÈÉ°', 29),\n",
       "  ('È≠èÈÉ°', 29),\n",
       "  ('ÁÇ∫ÈÉ°', 29),\n",
       "  ('ÂÆâÈÉ°', 28),\n",
       "  ('Áß¶ÈÉ°', 27)],\n",
       " set())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geonames_and_verbs('ÈÉ°', limits=(1, 4), top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to csv\n",
    "\n",
    "Let's only consider top 15 and limit in (1, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonames</th>\n",
       "      <th>occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ëî°Ê¥≤</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>È¨±Ê¥≤</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Â¥¢Â∂∏Ê¥≤</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Èï∑Ê¥≤</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ê°ëËêΩÊ¥≤</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>‰∫îÊ¥≤</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ê∫ßÊ¥≤</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Â±±Ê¥≤</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ê≥∞Â±±</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ê¢ÅÂ±±</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ÊúÉÁ®ΩÂ±±</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>‰∏≠Â±±</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>È´òÂ±±</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ÈôΩÂ±±</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ÂêçÂ±±</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ÂçóÂ±±</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Âª¨Â±±</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ÈçæÂ±±</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Âè≤Â±±</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geonames  occurrences\n",
       "0        Ëî°Ê¥≤           14\n",
       "1        È¨±Ê¥≤            9\n",
       "2       Â¥¢Â∂∏Ê¥≤            6\n",
       "3        Èï∑Ê¥≤            5\n",
       "4       Ê°ëËêΩÊ¥≤            4\n",
       "5        ‰∫îÊ¥≤            4\n",
       "6        Ê∫ßÊ¥≤            3\n",
       "7        Â±±Ê¥≤            3\n",
       "8        Ê≥∞Â±±           58\n",
       "9        Ê¢ÅÂ±±           40\n",
       "10      ÊúÉÁ®ΩÂ±±           28\n",
       "11       ‰∏≠Â±±           23\n",
       "12       È´òÂ±±           17\n",
       "13       ÈôΩÂ±±           17\n",
       "14       ÂêçÂ±±           16\n",
       "15       ÂçóÂ±±           15\n",
       "16       Âª¨Â±±           14\n",
       "17       ÈçæÂ±±           13\n",
       "18       Âè≤Â±±           12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_csv = []\n",
    "\n",
    "# Ê¥≤\n",
    "geo_names, _ = geonames_and_verbs('Ê¥≤', limits=(1, 4), top_n=15)\n",
    "geo_names = list(filter(lambda x: re.findall(r\"[ÊñºÁÇ∫‰ª•]\", x[0]) == [], geo_names))\n",
    "geo_csv += geo_names\n",
    "\n",
    "# Â±±\n",
    "geo_names, _ = geonames_and_verbs('Â±±', limits=(1, 4), top_n=15)\n",
    "geo_names = list(filter(lambda x: re.findall(r\"[ÊñºÁÇ∫‰ª•]\", x[0]) == [], geo_names))\n",
    "geo_csv += geo_names\n",
    "\n",
    "df = pd.DataFrame(geo_csv, columns=['geonames', 'occurrences'])\n",
    "df.to_csv('songshu_natural_geonames([Ê¥≤Â±±]).csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
